# Mixed-reality-squad-coordination-platform

Coordination and situation awareness are amongst the most important aspects of collaborative emergency response for firefighters, police, military soldiers, and so forth. Generally, command centers are in charge of managing a team, typically using voice communication, cameras, and possibly hand-held devices; and it is ideal to provide effective communication channels among team members too. Recent advancements in wearable display technology have introduced new tools to assist in such tasks.

This thesis builds a mixed-reality platform to assist the coordination of squads when performing tasks in real time. The platform provides tools to deliver visualization and heads up display (HUD) information to squad members, as well as reporting tools that allow squad members to coordinate with each other and their command center. The platform uses mixed reality devices (Microsoft HoloLens devices in this case) to synchronize member locations and other vital information across the team. Such a system allows dispatchers to efficiently exchange useful visual information, such as targets and paths, with field units. The example results demonstrate that this type of direct visual communication has many advantages over simply relying on voice communication and hand-held devices.

![](https://github.com/ImmersiveAnalyticsUNCC/Mixed-reality-squad-coordination-platform/blob/master/images/create-paths-01.jpg=250x250)
![](https://github.com/ImmersiveAnalyticsUNCC/Mixed-reality-squad-coordination-platform/blob/master/images/create-targets-01.jpg)
![](https://github.com/ImmersiveAnalyticsUNCC/Mixed-reality-squad-coordination-platform/blob/master/images/wim-01.jpg)

Publication: Elias Mahfoud, Mixed-reality squad-coordination platform, Master Thesis, UNC Charlotte, Dec. 2016.

[https://www.youtube.com/watch?v=tn6dlFz41o4&list=PLI1sj6AcDrkDFhBdjeuP9tj5kTNbAavgw](video)
